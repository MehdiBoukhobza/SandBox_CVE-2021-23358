from selenium import webdriver
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.common.by import By
import time
import json

# Path to your geckodriver
GECKODRIVER_PATH = '/usr/local/bin/geckodriver'

# Path to your Firefox profile
FIREFOX_PROFILE_PATH = '/home/ikigaikali/.mozilla/firefox/5lixxnhy.Selenium'

# URL of the webpage you want to scrape
URL = 'http://localhost:3000'

# Configure Firefox options
firefox_options = webdriver.FirefoxOptions()
firefox_options.add_argument('--headless')  # Run in headless mode if you don't want the browser UI

# Set the Firefox profile
profile = webdriver.FirefoxProfile(FIREFOX_PROFILE_PATH)
firefox_options.profile = profile

# Initialize WebDriver
service = Service(GECKODRIVER_PATH)
driver = webdriver.Firefox(service=service, options=firefox_options)

# Open the webpage
driver.get(URL)

# Allow some time for the page to load and Wappalyzer to analyze
time.sleep(10)  # Adjust the sleep time if necessary

# Retrieve Wappalyzer results using the browser console
try:
    # Inject and execute JavaScript to get Wappalyzer results
    script = """
    return Wappalyzer.analyze();
    """
    result = driver.execute_script(script)
    wappalyzer_results = json.loads(result)
    
    print("Technologies detected by Wappalyzer:")
    for technology in wappalyzer_results['technologies']:
        tech_name = technology['name']
        tech_categories = ', '.join(technology['categories'])
        print(f'{tech_name} ({tech_categories})')

finally:
    driver.quit()
